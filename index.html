<!DOCTYPE html>
<html>
  <head>
    <title>Grandpa AR - èªéŸ³æ§åˆ¶</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script src="https://aframe.io/releases/0.9.2/aframe.min.js"></script>
    <script src="https://cdn.rawgit.com/jeromeetienne/AR.js/1.7.5/aframe/build/aframe-ar.js"></script>
    <style>
      body {
        margin: 0;
        overflow: hidden;
      }

      .nav-btn {
        position: fixed;
        bottom: 20px;
        padding: 12px 24px;
        font-size: 16px;
        z-index: 10;
      }

      #prevBtn {
        left: 20px;
      }

      #nextBtn {
        right: 20px;
      }

      #voiceBtn {
        position: fixed;
        bottom: 80px;
        left: 50%;
        transform: translateX(-50%);
        padding: 12px 24px;
        font-size: 16px;
        z-index: 10;
      }

      #notice {
        position: fixed;
        top: 10px;
        left: 50%;
        transform: translateX(-50%);
        background-color: rgba(0, 0, 0, 0.75);
        color: white;
        padding: 10px 20px;
        font-size: 16px;
        border-radius: 8px;
        z-index: 100;
      }
    </style>
  </head>

  <body>
    <div id="notice">è«‹é»ä¸‹ã€ŒèªéŸ³è¼¸å…¥ã€æŒ‰éˆ•é–‹å§‹èªéŸ³è¾¨è­˜</div>
    <button id="voiceBtn">ğŸ¤ èªéŸ³è¼¸å…¥</button>
    <button id="prevBtn" class="nav-btn">ä¸Šä¸€é¡Œ</button>
    <button id="nextBtn" class="nav-btn">ä¸‹ä¸€é¡Œ</button>

    <a-scene embedded arjs="sourceType: webcam; debugUIEnabled: false;">
      <a-marker type="pattern" url="pattern-marker.patt">
        <a-entity
          id="grandpa"
          gltf-model="anime_girl.glb"
          position="0 0 0"
          rotation="0 0 0"
          scale="0.1 0.1 0.1">
        </a-entity>
      </a-marker>
      <a-entity camera></a-entity>
    </a-scene>

    <script>
      const notice = document.getElementById("notice");
      const prevBtn = document.getElementById("prevBtn");
      const nextBtn = document.getElementById("nextBtn");
      const voiceBtn = document.getElementById("voiceBtn");

      const questions = [
        { text: "é€™æ˜¯ç¬¬ä¸€é¡Œï¼Œè«‹ä»”ç´°è½ï¼" },
        { text: "é€™æ˜¯ç¬¬äºŒé¡Œï¼Œè«‹æº–å‚™å›ç­”ã€‚" },
        { text: "ç¬¬ä¸‰é¡Œé–‹å§‹å›‰ï¼ŒåŠ æ²¹ï¼" },
        { text: "é€™æ˜¯ç¬¬å››é¡Œï¼Œè¨˜å¾—æƒ³æ¸…æ¥šå†ä½œç­”ã€‚" }
      ];

      let currentIndex = 0;
      let gameStarted = false;

      function speak(text) {
        const msg = new SpeechSynthesisUtterance(text);
        msg.lang = "zh-TW";
        speechSynthesis.cancel();
        speechSynthesis.speak(msg);
        console.log("èªªè©±ï¼š", text);
      }

      function speakQuestion(index) {
        const q = questions[index];
        speak(q.text);
      }

      prevBtn.addEventListener("click", () => {
        if (!gameStarted) return;
        currentIndex = (currentIndex - 1 + questions.length) % questions.length;
        speakQuestion(currentIndex);
      });

      nextBtn.addEventListener("click", () => {
        if (!gameStarted) return;
        currentIndex = (currentIndex + 1) % questions.length;
        speakQuestion(currentIndex);
      });

      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

      if (SpeechRecognition) {
        const recognition = new SpeechRecognition();
        recognition.lang = "zh-TW";
        recognition.continuous = false;
        recognition.interimResults = false;

        recognition.onresult = (event) => {
          const transcript = event.results[0][0].transcript.trim();
          console.log("ä½¿ç”¨è€…èªªï¼š", transcript);

          if (transcript.includes("é–‹å§‹éŠæˆ²")) {
            if (!gameStarted) {
              gameStarted = true;
              notice.innerText = "éŠæˆ²é–‹å§‹å›‰ï¼";
              speak("å¥½çš„ï¼Œé–‹å§‹éŠæˆ²ï¼");
              setTimeout(() => {
                speakQuestion(currentIndex);
              }, 1500);
            }
          } else if (transcript.includes("ä¸‹ä¸€é¡Œ")) {
            nextBtn.click();
          } else if (transcript.includes("ä¸Šä¸€é¡Œ")) {
            prevBtn.click();
          } else {
            // å›è¦†ä½¿ç”¨è€…èªªçš„è©±
            speak("ä½ å‰›å‰›èªªçš„æ˜¯ï¼š" + transcript);
          }
        };

        recognition.onerror = (event) => {
          console.error("èªéŸ³è¾¨è­˜éŒ¯èª¤ï¼š", event.error);
          notice.innerText = "èªéŸ³è¾¨è­˜éŒ¯èª¤ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚";
        };

        voiceBtn.addEventListener("click", () => {
          try {
            recognition.start();
            notice.innerText = "è«‹é–‹å§‹èªªè©±...";
          } catch (err) {
            console.warn("èªéŸ³å•Ÿå‹•å¤±æ•—ï¼š", err);
            notice.innerText = "èªéŸ³å•Ÿå‹•å¤±æ•—ï¼Œè«‹ä½¿ç”¨ Chromeã€‚";
          }
        });
      } else {
        notice.innerText = "æ­¤ç€è¦½å™¨ä¸æ”¯æ´èªéŸ³è¾¨è­˜ï¼Œè«‹ä½¿ç”¨ Chrome é–‹å•Ÿæœ¬é ã€‚";
        console.warn("SpeechRecognition ä¸æ”¯æ´");
      }
    </script>
  </body>
</html>



